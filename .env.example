# bAIt-Chat Environment Configuration
# Copy this file to .env and fill in your values

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_BASE_URL=http://localhost:8000

# QServer Configuration
QSERVER_URL=http://localhost:60610
# QSERVER_API_KEY=your-api-key-if-required
DEFAULT_USER=bait_chat
DEFAULT_USER_GROUP=primary

# Databroker Configuration
DATABROKER_CATALOG=bluesky
# DATABROKER_HOST=localhost
# DATABROKER_PORT=5432

# LLM Configuration
# Choose one: openai, anthropic, mistral, lmstudio, ollama
LLM_PROVIDER=openai
LLM_MODEL=gpt-4

# API Keys (set the one for your chosen provider)
# OPENAI_API_KEY=sk-...
# ANTHROPIC_API_KEY=sk-ant-...
# MISTRAL_API_KEY=...

# Local LLM Configuration (for lmstudio/ollama)
# LMSTUDIO_BASE_URL=http://localhost:1234/v1
# OLLAMA_BASE_URL=http://localhost:11434
# LOCAL_MODEL_NAME=llama2
# LOCAL_MODEL_TEMPERATURE=0.7
# LOCAL_MODEL_MAX_TOKENS=4000
# LOCAL_MODEL_TIMEOUT=60

# Vector Database Configuration
VECTOR_DB_TYPE=chroma
VECTOR_DB_PATH=./vector_db
# For Qdrant (optional)
# QDRANT_URL=http://localhost:6333
# QDRANT_API_KEY=...

# Knowledge Base
KNOWLEDGE_BASE_PATH=./knowledge_base
AUTO_INDEX_ON_START=true

# Voice Configuration (Optional)
ENABLE_VOICE=false
WHISPER_MODEL=base
# WHISPER_API_URL=http://localhost:9000

# Security (Optional)
ENABLE_AUTH=false
AUTH_SECRET_KEY=change-me-in-production-use-a-long-random-string
AUTH_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Allowed Plans (comma-separated)
ALLOWED_PLANS=scan,count,list_scan,grid_scan,rel_scan,spiral,fly_scan

# Logging
LOG_LEVEL=INFO
LOG_FILE=./logs/bait_chat.log

# CORS (comma-separated origins)
CORS_ORIGINS=http://localhost:8501,http://localhost:3000,*

# Rate Limiting (Optional)
ENABLE_RATE_LIMIT=false
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_PERIOD=60

# Cache
ENABLE_CACHE=true
CACHE_TTL=300
CACHE_MAX_SIZE=1000

# Development
DEBUG=false
RELOAD=true

# WebSocket (for real-time updates)
ENABLE_WEBSOCKET=false
WS_HEARTBEAT_INTERVAL=30

# Performance
MAX_WORKERS=4
REQUEST_TIMEOUT=30